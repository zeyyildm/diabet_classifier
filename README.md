# ğŸ©º Diabetes Classification with Deep Learning (TensorFlow)

This project builds a deep-learning model using the **Pima Indians Diabetes Dataset** to predict whether a patient is likely to have diabetes based on several medical measurements.

The workflow includes **data analysis, preprocessing, train/validation/test splitting, scaling, model building with TensorFlow/Keras, training, and evaluation**.

---

## ğŸ“Œ 1. Project Overview

The goal of this project is to create a **neural network classifier** capable of predicting diabetes:

- **0 â†’ No Diabetes**
- **1 â†’ Diabetes**

A **Multi-Layer Perceptron (MLP)** model is trained using **TensorFlow/Keras** and evaluated on unseen test data to measure real performance.

---

## ğŸ“Š 2. Dataset

The dataset contains **768 samples** and the following **8 input features**:

- Pregnancies  
- Glucose  
- BloodPressure  
- SkinThickness  
- Insulin  
- BMI  
- DiabetesPedigreeFunction  
- Age  

ğŸ¯ **Target Variable:**
- `Outcome` â†’ 0 or 1

---

## ğŸ§¹ 3. Data Preprocessing

### ğŸ”¸ Handling Invalid Zero Values
Some medical features (e.g., **Glucose, BloodPressure, Insulin, BMI**) contain zeros, which are not realistic physiological values.  
These zeros were treated as **missing values** and replaced with the **median** of each column.

### ğŸ”¸ Train / Validation / Test Split
Data was split into:
- **70% Training**
- **15% Validation**
- **15% Test**

`stratify=y` was used to keep class distribution stable across all splits.

### ğŸ”¸ Feature Scaling
All input features were standardized with **StandardScaler**:
- Fit only on the **training set**
- Transform applied to **validation and test sets**

This prevents **data leakage** and ensures stable training.

---

## ğŸ§  4. Model Architecture (TensorFlow / Keras)

A simple but effective **Fully Connected Neural Network (MLP)** was built:

- Input Layer â†’ 8 features  
- Hidden Layer 1 â†’ `Dense(32)`, Activation: **ReLU**  
- Hidden Layer 2 â†’ `Dense(16)`, Activation: **ReLU**  
- Output Layer â†’ `Dense(1)`, Activation: **Sigmoid**

### âš™ï¸ Loss & Optimizer
- **Loss:** Binary Crossentropy  
- **Optimizer:** Adam  
- **Metric:** Accuracy  

---

## ğŸš€ 5. Model Training

The model was trained for **100 epochs** with **batch size = 32**, using the validation set to monitor generalization.

Training and validation accuracy were tracked across epochs to observe **model behavior and overfitting**.

---

## ğŸ“ˆ 6. Results

### âœ… Final Results

| Metric | Score |
|--------|--------|
| Training Accuracy | â‰ˆ 85.66% |
| Validation Accuracy | â‰ˆ 69.56% |
| Test Accuracy | â‰ˆ 76.72% |

### ğŸ“Š Interpretation

- The model performs **reasonably well** for this dataset  
  (â‰ˆ 76â€“78% accuracy is standard for Pima Diabetes).
- A gap between training and validation accuracy indicates **mild overfitting**, which is expected with small tabular datasets.
- Test accuracy reflects the modelâ€™s **real-world performance**, since test data was never used during training.

---

## ğŸ“‰ 7. Evaluation Visualizations

The project includes the following visualizations:

- âœ… **Confusion Matrix**

---

## ğŸ”§ 8. Possible Improvements

The following methods could improve performance:

- Add **Dropout** to reduce overfitting  
- Add **Batch Normalization**  
- Use **EarlyStopping**  
- Try more complex architectures  
- Tune hyperparameters (learning rate, layer sizes, etc.)

---

## ğŸ“ 9. Technologies Used

- ğŸ Python  
- ğŸ§® Pandas / NumPy  
- ğŸ“Š Scikit-Learn  
- ğŸ§  TensorFlow / Keras  
- ğŸ“ˆ Matplotlib / Seaborn  
